name: Scrape, Build, and Deploy

on:
  push:
    branches: [ "main" ]
  schedule:
    - cron: "13 6 * * *"
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build-deploy:
    runs-on: ubuntu-24.04
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
            python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          python -m playwright install --with-deps chromium

      - name: Ensure src package init
        run: test -f src/__init__.py || printf "" > src/__init__.py

      - name: Scrape
        env:
          USE_PLAYWRIGHT: 1
        run: python -m src.main

      - name: Postprocess normalize + build ICS
        env:
          JSONLD_ENABLE: "1"         # set "0" to completely disable enrichment
          JSONLD_MAX: "80"           # hard cap on fetches per run
          JSONLD_PER_DOMAIN: "15"    # per-domain cap
          JSONLD_TIMEOUT: "4"        # seconds
        run: python src/postprocess.py

      - name: Stage site artifacts
        run: |
          mkdir -p public/state public/ics
          cp -f state/last_run_report.json public/state/last_run_report.json || true
          cp -f state/validation.json public/state/validation.json || true
          cp -f state/events.json public/state/events.json || true
          cp -f northwoods.ics public/ics/northwoods.ics || true

      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: public
          name: github-pages
          retention-days: 1

      - name: Deploy to GitHub Pages
        uses: actions/deploy-pages@v4
