name: Scrape & Parse Events
on:
  # Manual run
  workflow_dispatch: {}
  # Nightly auto-run (UTC)
  schedule:
    - cron: "22 10 * * *"
  # Also run automatically AFTER CI completes successfully on main
  workflow_run:
    workflows: ["Python CI"]
    types: [completed]
    branches: [main]

concurrency:
  group: scrape-events
  cancel-in-progress: true

jobs:
  scrape:
    # Only proceed if the upstream CI finished successfully
    if: ${{ github.event_name != 'workflow_run' || github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt || true
          pip install playwright beautifulsoup4 requests pyyaml

      - name: Install Playwright (Chromium + system deps)
        run: python -m playwright install --with-deps chromium

      - name: Run scraper
        env:
          NW_TZ: America/Chicago
        run: |
          # If your code reads sources.yml from the repo:
          python src/main.py

          # If you prefer passing inline JSON instead, replace the line above with:
          # python src/main.py <<'JSON'
          # [ { "name": "Vilas County (Modern Tribe)", "url": "https://vilaswi.com/events/?eventDisplay=list", "kind": "modern_tribe" } ]
          # JSON

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-output
          path: |
            last_run_report.json
            state/last_run_report.json
            state/snapshots/**
